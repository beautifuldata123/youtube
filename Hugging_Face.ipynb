{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hugging Face.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2hGyvy3ESiy"
      },
      "source": [
        "**Installation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Fk-kfKbEQzP"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jc0fdyH28Nec"
      },
      "source": [
        "#conda install -c huggingface transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8K-6Ap5e8_kn"
      },
      "source": [
        "\n",
        "[Hugging Face Documentation](https://huggingface.co/transformers)\n",
        "\n",
        "[Models ](https://huggingface.co/models)\n",
        "\n",
        "Summary\n",
        "*  Sentiment Analysis\n",
        "*  Question Answering System\n",
        "*  Masked Modelling\n",
        "*  Text Generation\n",
        "*  NER\n",
        "*  Summarization\n",
        "*  Translation \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVnDCSygDVfc"
      },
      "source": [
        "from transformers import pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLokhxdEFylM"
      },
      "source": [
        "***Sentiment Analysis***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzaL_glOEHgm"
      },
      "source": [
        "sa = pipeline('sentiment-analysis')\n",
        "sa('i am  not happy about this')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEoQAWF1-3wa"
      },
      "source": [
        "sa.model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KP5r71vUFnOc"
      },
      "source": [
        "sa(['i am happy about this','i dont think it will work'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uY26g-JYHNAj"
      },
      "source": [
        "Load From Local\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX617dDzFrNw"
      },
      "source": [
        "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "classifier = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5XJsvJHHMSR"
      },
      "source": [
        "***Question Answering System***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-jnmFEGIK7Y"
      },
      "source": [
        "qa = pipeline(\"question-answering\",model=\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M70agV8nIRgI"
      },
      "source": [
        "context = r\"\"\"Extractive Question Answering is the task of extracting an answer from a text given a question. An example of a question answering dataset is the SQuAD dataset, which is entirely based on that task. If you would like to fine-tune a model on a SQuAD task, you may leverage the examples/question-answering/run_squad.py script.\"\"\"\n",
        "result = qa(question=\"What is extractive question answering?\", context=context)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAO3Kn-EI9Rg"
      },
      "source": [
        "***Masked Modelling***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzgT0B-3IdN0"
      },
      "source": [
        "mask = pipeline(\"fill-mask\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ocvcm0NJLQC"
      },
      "source": [
        "mask.tokenizer.mask_token"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3YSF7E3JQzS"
      },
      "source": [
        "mask(\"let's see <mask> we can do with this\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "St2X3ABoJn3F"
      },
      "source": [
        "***Text Generation***\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6ynVKZvJc37"
      },
      "source": [
        "text_generator = pipeline(\"text-generation\") #default GPT-2 model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ad2SiILSJupv"
      },
      "source": [
        "text_generator(\"As far as I am concerned, I will\", max_length=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQkrJvp3KOZq"
      },
      "source": [
        "***NER***\n",
        "\n",
        "\n",
        "\n",
        "*   O, Outside of a named entity\n",
        "\n",
        "* B-MIS, Beginning of a miscellaneous entity right after another miscellaneous entity\n",
        "\n",
        "* I-MIS, Miscellaneous entity\n",
        "\n",
        "* B-PER, Beginning of a person’s name right after another person’s name\n",
        "\n",
        "* I-PER, Person’s name\n",
        "\n",
        "* B-ORG, Beginning of an organisation right after another organisation\n",
        "\n",
        "* I-ORG, Organisation\n",
        "\n",
        "* B-LOC, Beginning of a location right after another location\n",
        "\n",
        "* I-LOC, Location\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvygFeHYKB0S"
      },
      "source": [
        "ner = pipeline(\"ner\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHyKTO7JKUEU"
      },
      "source": [
        "ner('Google hears everything paul says')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hMgFpfTLMX0"
      },
      "source": [
        "***Summarization***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9k3bbLEMKoPV"
      },
      "source": [
        "summarizer = pipeline(\"summarization\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lE_K0JkZ8CHR"
      },
      "source": [
        "ARTICLE = \"\"\"Modern hard drives feature an ability to recover from some read/write errors by internally remapping sectors and performing other forms of self-test and recovery. The process for this can sometimes take several seconds or (under heavy usage) minutes, during which time the drive is unresponsive. Hardware RAID controllers and software RAID implementations are designed to recognise a drive which does not respond within a few seconds, and mark it as unreliable, indicating that it should be withdrawn from use and the array rebuilt from parity data. This is a long process, degrades performance, and if more drives fail under the resulting additional workload, it may be catastrophic.\n",
        "\n",
        "If the drive itself is inherently reliable but has some bad sectors, then TLER and similar features prevent a disk from being unnecessarily marked as 'failed' by limiting the time spent on correcting detected errors before advising the array controller of a failed operation. The array controller can then handle the data recovery for the limited amount involved, rather than marking the entire drive as faulty.\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Pc5jrpO8ect"
      },
      "source": [
        "summarizer(ARTICLE, max_length=100, min_length=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDT9FX4R8ovD"
      },
      "source": [
        "***Translation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnA0qF-58iuJ"
      },
      "source": [
        "translator = pipeline(\"translation_en_to_de\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e9x4yXa8xpn"
      },
      "source": [
        "translator(\"Hugging Face is a technology company based in New York and Paris\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WaVosxqJ_wH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}